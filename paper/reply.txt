We thank the Editor for seeking advice from two referees, one for the
science the other for the statistics. Below we attach our reply to
both of them.  

We also attach an updated version of the paper highlighting the places
where changes were made.

Best regards,

The Authors.



----------------------------
REPLY TO THE SCIENCE REFEREE
----------------------------

(1) The paper should include a clearer discussion on whether the
authors think the detected bias in the standard concentration
measurement methods has significantly affected the c(M) relations
reported in the literature.

Reply to (1). We have included that discussion at the end of section
5.2 "Impact on the Mass-Concentration relationship". We only discuss
two of the most recent results Ludlow+2016 and Klypin+2016. As a
summary, they already have cuts on 5000 particles, so their results
should be OK. However, because of the limitation on their simulations
they cannot go below 10^12 Msun. Clearly, the result by Prada+2012
that we use as a benchmark (given that we also use Bolshoi) are in
disagreement as we highlight in the same section 5.2. 

(2) The new method proposed by the authors involves an MCMC approach
to sample the likelihood function for the concentration value. More
information about how this is done precisely and especially how long
it takes in terms of CPU time needs to be included. I note that modern
simulations involve millions of halos, especially of small size... It
may easily become prohibitive to run a MCMC chain for each of them!
(Especially using slow Python code.)

Reply to (2). It is rather slow. A halo of 2K particles takes 1 second
to fit. We mention the timing results at the end of section 3.2
"Estimate from the integrated mass profile".
In spite of this, the fitting procedure is trivially parallel as it
can run on different halos. Emcee can also take advantage of multicore
architectures. So it should be possible to manage a large modern simulation
with sufficient amount of cores. A fit to a simulation with 1 million
halos could run under two days using 128 cores.  

(3) The authors make the assumption that the bias involved in the
concentration measurements of simulation halos containing a low number
of halos can be estimated by randomly down-sampling a well-resolved
halo, and then seeing how this changes its concentration
estimate. This implicitly makes the assumption that the halo structure
of simulated halos with a few hundred particles can be "trusted",
i.e. is equivalent to a downsampled version of the same halo in a
simulation with many more particles. This is not really evident,
however, because there could be other sources of numerical effects
that spoil the convergence of halo structure at that level, and hence
would introduce additional biases in the halo concentration. For
example, two-body relaxation effects may change the concentration of
halos composed of a few hundred particles. The authors should discuss
this issue in detail. (I note that some comparisons of concentrations
of the same halos at different resolution is for example contained in
Springel et al. 2008, MNRAS, 391, 1685.)


Reply to (3). We agree that it is difficult to see why the subsample
with a lower particle number should be trusted. We can at least be
sure of that in the statistical sense, which is the most relevant for
us as it is a requirement to do bootstrapping. 
As a check we perform a two-sample Kolmogorov-Smirnov test between the radial
distances of the subsamples and its parent halo. This KS test returns
a p-value which in turn can be used to build a p-value distribution
using the results from all the subsamples. 
We found that the p-value distribution is flat, meaning that the
radial distribution of particles (our distribution of interest) for
the bootstrapping subsets cannot be distinguished (in the statistical
sense) from that of its parent halo distribution.
We now mention that at the beginning of Section 5.1 "Bootstraping to
estimate biases". 
We wish to highlight here (not in the paper) that it is actually easy
to get the subsampling wrong by, for instance, subsampling a list of
radial distances that has already some correlation in it (i.e. it is
ranked by radial distance or values of the gravitational potential). 
We also mention in the middle of Section 5.1 the approach by
Springel+2008 of performing different simulations of the same halo. To
summarize, they don't find any bias because their lowest resolution is
close to 10^5 particles, well above the threshold of 4000 where we
detect the differences. 


----------------------------
REPLY TO THE STATISTICS REFEREE
----------------------------

"It was very difficult to understand what was going on in this. 

It is not clear what the authors meant by biases: 
bias = expectation - estimate (statistical terms) or selection bias? 
It looks like bootstrapping is used to estimate variance eq(8). 
r_i are increasing and M_i are also increasing. 
As the values (m_i, x_i) are derived from these ranked values, 
the summends in eq (9) are very unlikely to be independent. 
Classical bootstrapping does not work for dependent values. 
So the results are suspect."

We found the comments from the referee difficult to unpack. 
Specially difficult to understand was the statement "Results are
suspect.". This is because there are at least four new results in our
paper, and the parts/statements that caused confusion to the
statistician are not explicitly quoted in her/his comment to
understand which results are suspect.  

Let us first recall that the main results of our paper are:

1) Use of bootstrapping to estimate biases in concentration estimates.
2) Use of bootstrapping to estimate uncertainties in concentration estimates.
3) Use the integrated mass profile to estimate concentration.
4) Use of bootstrapping to approximate a covariance matrix in a max
likelihood computation. 

Only points 1), 2) and 4) use bootstrapping which seems to be the
major point of concern. 
Here we argue why 1) and 2) should not be suspect, how 4) is difficult
to do (as we acknowledge in the paper) and why 4) is anyway irrelevant to
ensure that 3) is done correctly. 

We also include a brief summary of astrophysical concepts addressed to
the statistician, which might help to clarify what we do in the paper.  

1. Basic astrophysical concepts.

Most astrophysicists believe that there is fluid permeating the whole Universe
called dark matter. This fluid can be though as a continuous density field.
Expensive Monte-Carlo computational simulations sample this density field
with point mass particles.
Astrophysicists have found that in the densest regions this point mass
distribution can be can be approximated as a) spherical and b) as coming from
a parent radial mass  distribution (RMDD) which can be characterized
by a scalar parameter called the concentration, C.  
We are concerned with algorithms that estimate the concentration from
a set of a set of radial measurements R=(r_1,...,r_N) of the point
mass particles coming directly from the expensive Monte Carlo
simulation.  

2. Estimating biases with bootstrapping.

Starting from a set R with large N (N=10^6) coming directly from the expensive 
Monte-Carlo simulation we assume that it is a fair sample of the parent RMDD.
Each point r_i we use is an independent measure of other r_j. 
That means that we do not ignore, add, or change r_i values depending
on other r_j. 
That could happen if, for instance, we removed randomly very clustered
r_i values around some r_j  (i.e. tried to smooth out clumps).  
   
We bootstrap R. We denote each bootstrapped set of N* points as R*.
We use a Kolmogorov-Smirnov to compare each of the hundreds of R* with
the parent R.  From this test we find a flat distribution of p-values
indicating that the R* subsets are a fair subsamples of R. 

Then, we estimate the concentration on R and use this as the correct
estimated value C. 
Using the same estimator we get the concentrations C* on the R* samples.
We define the bias as the average of the differences (C*-C). 

We use this to show that two commonly used methods to estimate the
concentration have a growing bias as the particle numbers decreases,
while the new method we present has a bias close to zero (Figure 1). 

We use the same logic to find the variances (lines in Figure 2).

3. Covariance matrices in the new method to estimate the concentration.

(This is probably the point the statistician is worried about.)
The new method to get the concentration from a set R uses an
approximated diagonal covariance matrix estimated from bootstrapping. 
We know that the m_i are not independent (as the referee points out)
and that's why we try to estimate the covariance matrix. 

But we do not bootstrap the (r_i, m_i) pairs! We bootstrap the r_i as
we explained before.  If we did bootstrapping on the (r_i, m_i) we
wouldn't find the variance in Eq. 8 as all the points for an given
value of $r$ would fall on top of each other for the same value of $m$.

We stress in the text that the diagonal inverse covariance matrix we
use is only an approximation. 
The good news is that the choice for the variances sigma_i in Eq. 9 does
not change the optimal result. That only changes the size of the error
bars. 

For instance, if we use N (the number of points in R) as the variance in the
chi^2 expression (Eq. 9) we find the same uncertainties as estimated
by the bootstrapping computations described in the part 2. of this
reply (the continuous lines in Fig 2). 





