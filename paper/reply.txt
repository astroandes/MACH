We thank the Editor for seeking advice from a statistician and
forwarding us his/her comments.
However, we found the comments difficult to unpack. 


---------------------------------------------------------------------- 

(1) The paper should include a clearer discussion on whether the
authors think the detected bias in the standard concentration
measurement methods has significantly affected the c(M) relations
reported in the literature.

(2) The new method proposed by the authors involves an MCMC approach
to sample the likelihood function for the concentration value. More
information about how this is done precisely and especially how long
it takes in terms of CPU time needs to be included. I note that modern
simulations involve millions of halos, especially of small size... It
may easily become prohibitive to run a MCMC chain for each of them!
(Especially using slow Python code.)

(3) The authors make the assumption that the bias involved in the
concentration measurements of simulation halos containing a low number
of halos can be estimated by randomly down-sampling a well-resolved
halo, and then seeing how this changes its concentration
estimate. This implicitly makes the assumption that the halo structure
of simulated halos with a few hundred particles can be "trusted",
i.e. is equivalent to a downsampled version of the same halo in a
simulation with many more particles. This is not really evident,
however, because there could be other sources of numerical effects
that spoil the convergence of halo structure at that level, and hence
would introduce additional biases in the halo concentration. For
example, two-body relaxation effects may change the concentration of
halos composed of a few hundred particles. The authors should discuss
this issue in detail. (I note that some comparisons of concentrations
of the same halos at different resolution is for example contained in
Springel et al. 2008, MNRAS, 391, 1685.)


Reply to (3). We agree that it is difficult to see why the subsample
with a lower particle number should be trusted. To be sure of it, we 
performed a two-sample Kolmogorov-Smirnov test between the radial
distances of the subsamples and its parent halo. This KS test returns
a p-value which in turn can be used to build a p-value distribution
using the results from all the subsamples. 

We found that the p-value distribution is flat, meaning that the
radial distribution of particles (our distribution of interest) for
the bootstrapping subsets cannot be distiguished (in the statistical
sense) from that of its parent halo distribution.

We highligh that it is actually easy to get the subsampling wrong by,
for instance, subsampling a list of radial distances that has already
some correlation in it (i.e. it is ranked by radial distance or values
of the gravitational potential). 

We mention the KS test at the end of the first paragraph of Section
5.1 "Bootsrapping to estimate biases". 




Specially difficult to understand was the statement "Results are
suspect.". This is because there are at least four new results in our
paper, and the parts/statements that caused confusion to the
statistician are not explicitly quoted in her/his comment to understand which
results are suspect. 

We kindly request this reply to be forwarded both to the statistician
and the referee on the science aspect of the paper. 

Let us first recall that the main results of our paper are:

1) Use of bootstrapping to estimate biases in concentration estimates.
2) Use of bootstrapping to estimate uncertainties in concentration estimates.
3) Use the integrated mass profile to estimate concentration.
4) Use of bootstrapping to approximate a covariance matrix in a max
likelihood computation. 

Only points 1), 2) and 4) use bootstrapping which seems to be the
major point of concern. 
Here we argue why 1) and 2) should not be suspect, how 4) is difficult
to do (as we acknowledge in the paper) and why 4) is anyway irrelevant to
ensure that 3) is done correctly. 

We also include a brief summary of astrophysical concepts addressed to
the statistician, which might help to clarify what we do in the paper.  

1. Basic astrophysical concepts.

Most astrophysicists believe that there is fluid permeating the whole Universe
called dark matter. This fluid can be though as a continuous density field.
Expensive Monte-Carlo computational simulations sample this density field
with point mass particles.
Astrophysicists have found that in the densest regions this point mass
distribution can be can be approximated as a) spherical and b) as coming from
a parent radial mass  distribution (RMDD) which can be characterized
by a scalar parameter called the concentration, C.  
We are concerned with algorithms that estimate the concentration from
a set of a set of radial measurements R=(r_1,...,r_N) of the point
mass particles coming directly from the expensive Monte Carlo
simulation.  

2. Estimating biases with bootstrapping.

Starting from a set R with large N (N=10^6) coming directly from the expensive 
Monte-Carlo simulation we assume that it is a fair sample of the parent RMDD.
Each point r_i we use is an independent measure of other r_j. 
That means that we do not ignore, add, or change r_i values depending
on other r_j. 
That could happen if, for instance, we removed randomly very clustered
r_i values around some r_j  (i.e. tried to smooth out clumps).  
   
We bootstrap R. We denote each bootstrapped set of N* points as R*.
We use a Kolmogorov-Smirnov to compare each of the hundreds of R* with
the parent R.  From this test we find a flat distribution of p-values
indicating that the R* subsets are a fair subsamples of R. 

Then, we estimate the concentration on R and use this as the correct
estimated value C. 
Using the same estimator we get the concentrations C* on the R* samples.
We define the bias as the average of the differences (C*-C). 

We use this to show that two commonly used methods to estimate the
concentration have a growing bias as the particle numbers decreases,
while the new method we present has a bias close to zero (Figure 1). 

We use the same logic to find the variances (lines in Figure 2).

3. Covariance matrices in the new method to estimate the concentration.

(This is probably the point the statistician is worried about.)
The new method to get the concentration from a set R uses an
approximated diagonal covariance matrix estimated from bootstrapping. 
We know that the m_i are not independent (as the referee points out)
and that's why we try to estimate the covariance matrix. 

But we do not bootstrap the (r_i, m_i) pairs! We bootstrap the r_i as
we explained before.  If we did bootstrapping on the (r_i, m_i) we
wouldn't find the variance in Eq. 8 as all the points for an given
value of $r$ would fall on top on the same value of $m$.

We stress in the text that the diagonal inverse covariance matrix we
use is only an approximation. 
The good news is that the choice for the variances sigma_i in Eq. 9 does
not change the optimal result. They only change the size of the error
bars. 

For instance, if we use N (the number of points in R) as the variance in the
chi^2 expression (Eq. 9) we find the same uncertainties as estimated
by the bootstrapping computations described in the part 2. of this
reply (the continuous lines in Fig 2). 





